{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Data Cleaning\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# stats\n",
    "from statsmodels.api import tsa # time series analysis\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df = pd.read_csv('../../data/microsoft_data.csv', index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking datatypes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1259 entries, 2019-07-29 to 2024-07-29\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       1259 non-null   float64\n",
      " 1   High       1259 non-null   float64\n",
      " 2   Low        1259 non-null   float64\n",
      " 3   Close      1259 non-null   float64\n",
      " 4   Adj Close  1259 non-null   float64\n",
      " 5   Volume     1259 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 68.9+ KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Date to be datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.index = pd.to_datetime(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1259 entries, 2019-07-29 to 2024-07-29\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       1259 non-null   float64\n",
      " 1   High       1259 non-null   float64\n",
      " 2   Low        1259 non-null   float64\n",
      " 3   Close      1259 non-null   float64\n",
      " 4   Adj Close  1259 non-null   float64\n",
      " 5   Volume     1259 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 68.9 KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "Remaining datatypes are numerical and so we can continue with data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for missing dates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting first and last day\n",
    "first_day = msft_df.index.min()\n",
    "last_day = msft_df.index.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1827 days 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate difference between last and first day\n",
    "last_day -  first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "There is a difference of 568 days, which is due to the absence of records for weekend dates. Given that this dataset is based on stock price data, I will intentionally leave gaps in the date range for weekends to accurately reflect the non-trading days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate full date range between first and last day\n",
    "# Using freq B to ensure dates reflect business days (excludes weekends and BHs)\n",
    "full_range = pd.date_range(start=first_day, end=last_day, freq=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = full_range.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "There are 47 missing days over the 5-year period. I will review these missing dates to determine if there is an underlying reason as to they are missing. Given that Yahoo Finance typically provides a clean dataset, I expect there may be specific reasons for these missing days, especially after considering business days only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-09-02', '2019-11-28', '2019-12-25', '2020-01-01',\n",
       "               '2020-01-20', '2020-02-17', '2020-04-10', '2020-05-25',\n",
       "               '2020-07-03', '2020-09-07', '2020-11-26', '2020-12-25',\n",
       "               '2021-01-01', '2021-01-18', '2021-02-15', '2021-04-02',\n",
       "               '2021-05-31', '2021-07-05', '2021-09-06', '2021-11-25',\n",
       "               '2021-12-24', '2022-01-17', '2022-02-21', '2022-04-15',\n",
       "               '2022-05-30', '2022-06-20', '2022-07-04', '2022-09-05',\n",
       "               '2022-11-24', '2022-12-26', '2023-01-02', '2023-01-16',\n",
       "               '2023-02-20', '2023-04-07', '2023-05-29', '2023-06-19',\n",
       "               '2023-07-04', '2023-09-04', '2023-11-23', '2023-12-25',\n",
       "               '2024-01-01', '2024-01-15', '2024-02-19', '2024-03-29',\n",
       "               '2024-05-27', '2024-06-19', '2024-07-04'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "On investigating the missing dates, it looks like they correspond to US bank holidays. Since the stock market is closed on these dates, we should exclude them in addition to weekends when analysing the dataset. To do this, I will use `holidays` library and `CustomBusinessDay` module to include US bank holidays in the list of dates to exclude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bank_hols = holidays.UnitedStates(years=[2019,2020,2021,2022,2023,2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now excluding weekends AND US bank holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=us_bank_hols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcualting full date range between first and last day\n",
    "# Now excluding weekends and US holidays \n",
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-04-10', '2021-04-02', '2022-04-15', '2023-04-07',\n",
       "               '2024-03-29'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "Only 5 dates missing now, one per year which is intereseting.\n",
    "\n",
    "After looking into these dates futher, it appears these dates represent Good Friday holiday for each year. For some reason these holidays were not exlcuded in us_bank_hols: \n",
    "\n",
    "    April 10, 2020: Good Friday\n",
    "    April 2, 2021: Good Friday\n",
    "    April 15, 2022: Good Friday\n",
    "    April 7, 2023: Good Friday\n",
    "    March 29, 2024: Good Friday\n",
    "\n",
    "\n",
    "To proceed with cleaning as there are no missing dates which require propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Good Friday dates (for 2019 to 2024)\n",
    "good_fridays = pd.to_datetime([\n",
    "    '2019-04-19',  # Good Friday 2019\n",
    "    '2020-04-10',  # Good Friday 2020\n",
    "    '2021-04-02',  # Good Friday 2021\n",
    "    '2022-04-15',  # Good Friday 2022\n",
    "    '2023-04-07',  # Good Friday 2023\n",
    "    '2024-03-29',  # Good Friday 2024\n",
    "])\n",
    "\n",
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom business day calendar including these holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "I have decided not to use interpolation to 'fill' the missing dates in my stock market data. The missing dates occur on days when the stock market is not open, such as weekends and bank holidays. Interpolating data for non-trading days could lead to unreliable results and insights since there are no actual market transactions or price changes during these periods.\n",
    "\n",
    "Moving forward, I will explore the effect of aggregating the data to address the issue of missing dates due to market closures. Timeseries analysis requires a continuous date range, and since interpolation is not a suitable choice in this context, I will aggregate the data to a weekly/monthly level.\n",
    "\n",
    "CHANGE TO SAY BANK HOLIODAYS/ WEEKENDS NEED TRO BE FILLED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "As expected, there are no missing values in the dataset. Yahoo Finance provides a clean dataset with minimal need for data cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing dates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with a DateTime index\n",
    "# Reindex to include all days (daily frequency)\n",
    "full_index = pd.date_range(start=msft_df.index.min(), end=msft_df.index.max(), freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df = msft_df.reindex(full_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation\n",
    "msft_df= msft_df.interpolate(method='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>141.500000</td>\n",
       "      <td>141.509995</td>\n",
       "      <td>139.369995</td>\n",
       "      <td>141.029999</td>\n",
       "      <td>134.499710</td>\n",
       "      <td>1.660590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30</th>\n",
       "      <td>140.139999</td>\n",
       "      <td>141.220001</td>\n",
       "      <td>139.800003</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>133.851212</td>\n",
       "      <td>1.684650e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-31</th>\n",
       "      <td>140.330002</td>\n",
       "      <td>140.490005</td>\n",
       "      <td>135.080002</td>\n",
       "      <td>136.270004</td>\n",
       "      <td>129.960098</td>\n",
       "      <td>3.859880e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>140.940002</td>\n",
       "      <td>136.929993</td>\n",
       "      <td>138.059998</td>\n",
       "      <td>131.667221</td>\n",
       "      <td>4.055750e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>138.089996</td>\n",
       "      <td>138.320007</td>\n",
       "      <td>135.259995</td>\n",
       "      <td>136.899994</td>\n",
       "      <td>130.560913</td>\n",
       "      <td>3.079160e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>428.799988</td>\n",
       "      <td>429.799988</td>\n",
       "      <td>417.510010</td>\n",
       "      <td>418.399994</td>\n",
       "      <td>418.399994</td>\n",
       "      <td>2.994380e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-26</th>\n",
       "      <td>418.200012</td>\n",
       "      <td>428.920013</td>\n",
       "      <td>417.269989</td>\n",
       "      <td>425.269989</td>\n",
       "      <td>425.269989</td>\n",
       "      <td>2.356650e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-27</th>\n",
       "      <td>422.650004</td>\n",
       "      <td>429.996673</td>\n",
       "      <td>419.748057</td>\n",
       "      <td>426.313324</td>\n",
       "      <td>426.313324</td>\n",
       "      <td>1.841836e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-28</th>\n",
       "      <td>427.099996</td>\n",
       "      <td>431.073334</td>\n",
       "      <td>422.226125</td>\n",
       "      <td>427.356659</td>\n",
       "      <td>427.356659</td>\n",
       "      <td>1.327022e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29</th>\n",
       "      <td>431.549988</td>\n",
       "      <td>432.149994</td>\n",
       "      <td>424.704193</td>\n",
       "      <td>428.399994</td>\n",
       "      <td>428.399994</td>\n",
       "      <td>8.122076e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "2019-07-29  141.500000  141.509995  139.369995  141.029999  134.499710   \n",
       "2019-07-30  140.139999  141.220001  139.800003  140.350006  133.851212   \n",
       "2019-07-31  140.330002  140.490005  135.080002  136.270004  129.960098   \n",
       "2019-08-01  137.000000  140.940002  136.929993  138.059998  131.667221   \n",
       "2019-08-02  138.089996  138.320007  135.259995  136.899994  130.560913   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-07-25  428.799988  429.799988  417.510010  418.399994  418.399994   \n",
       "2024-07-26  418.200012  428.920013  417.269989  425.269989  425.269989   \n",
       "2024-07-27  422.650004  429.996673  419.748057  426.313324  426.313324   \n",
       "2024-07-28  427.099996  431.073334  422.226125  427.356659  427.356659   \n",
       "2024-07-29  431.549988  432.149994  424.704193  428.399994  428.399994   \n",
       "\n",
       "                  Volume  \n",
       "2019-07-29  1.660590e+07  \n",
       "2019-07-30  1.684650e+07  \n",
       "2019-07-31  3.859880e+07  \n",
       "2019-08-01  4.055750e+07  \n",
       "2019-08-02  3.079160e+07  \n",
       "...                  ...  \n",
       "2024-07-25  2.994380e+07  \n",
       "2024-07-26  2.356650e+07  \n",
       "2024-07-27  1.841836e+07  \n",
       "2024-07-28  1.327022e+07  \n",
       "2024-07-29  8.122076e+06  \n",
       "\n",
       "[1828 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting dataframe to csv\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.to_csv('../../data/microsoft_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "\n",
    "- format of graphs\n",
    "- add intro/conc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
