{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Data Cleaning\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# stats\n",
    "from statsmodels.api import tsa # time series analysis\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df = pd.read_csv('../../data/microsoft_data.csv', index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking datatypes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1259 entries, 2019-07-29 to 2024-07-29\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       1259 non-null   float64\n",
      " 1   High       1259 non-null   float64\n",
      " 2   Low        1259 non-null   float64\n",
      " 3   Close      1259 non-null   float64\n",
      " 4   Adj Close  1259 non-null   float64\n",
      " 5   Volume     1259 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 68.9+ KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Date to be datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.index = pd.to_datetime(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1259 entries, 2019-07-29 to 2024-07-29\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       1259 non-null   float64\n",
      " 1   High       1259 non-null   float64\n",
      " 2   Low        1259 non-null   float64\n",
      " 3   Close      1259 non-null   float64\n",
      " 4   Adj Close  1259 non-null   float64\n",
      " 5   Volume     1259 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 68.9 KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "Remaining datatypes are numerical and so we can continue with data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for missing dates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting first and last day\n",
    "first_day = msft_df.index.min()\n",
    "last_day = msft_df.index.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1827 days 00:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate difference between last and first day\n",
    "last_day -  first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "There is a difference of 568 days, which is due to the absence of records for weekend dates. Given that this dataset is based on stock price data, I will intentionally leave gaps in the date range for weekends to accurately reflect the non-trading days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate full date range between first and last day\n",
    "# Using freq B to ensure dates reflect business days (excludes weekends and BHs)\n",
    "full_range = pd.date_range(start=first_day, end=last_day, freq=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = full_range.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "There are 47 missing days over the 5-year period. I will review these missing dates to determine if there is an underlying reason as to they are missing. Given that Yahoo Finance typically provides a clean dataset, I expect there may be specific reasons for these missing days, especially after considering business days only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-09-02', '2019-11-28', '2019-12-25', '2020-01-01',\n",
       "               '2020-01-20', '2020-02-17', '2020-04-10', '2020-05-25',\n",
       "               '2020-07-03', '2020-09-07', '2020-11-26', '2020-12-25',\n",
       "               '2021-01-01', '2021-01-18', '2021-02-15', '2021-04-02',\n",
       "               '2021-05-31', '2021-07-05', '2021-09-06', '2021-11-25',\n",
       "               '2021-12-24', '2022-01-17', '2022-02-21', '2022-04-15',\n",
       "               '2022-05-30', '2022-06-20', '2022-07-04', '2022-09-05',\n",
       "               '2022-11-24', '2022-12-26', '2023-01-02', '2023-01-16',\n",
       "               '2023-02-20', '2023-04-07', '2023-05-29', '2023-06-19',\n",
       "               '2023-07-04', '2023-09-04', '2023-11-23', '2023-12-25',\n",
       "               '2024-01-01', '2024-01-15', '2024-02-19', '2024-03-29',\n",
       "               '2024-05-27', '2024-06-19', '2024-07-04'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "On investigating the missing dates, it looks like they correspond to US bank holidays. Since the stock market is closed on these dates, we should exclude them in addition to weekends when analysing the dataset. To do this, I will use `holidays` library and `CustomBusinessDay` module to include US bank holidays in the list of dates to exclude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bank_hols = holidays.UnitedStates(years=[2019,2020,2021,2022,2023,2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now excluding weekends AND US bank holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=us_bank_hols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcualting full date range between first and last day\n",
    "# Now excluding weekends and US holidays \n",
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-04-10', '2021-04-02', '2022-04-15', '2023-04-07',\n",
       "               '2024-03-29'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "Only 5 dates missing now, one per year which is intereseting.\n",
    "\n",
    "After looking into these dates futher, it appears these dates represent Good Friday holiday for each year. For some reason these holidays were not exlcuded in us_bank_hols: \n",
    "\n",
    "    April 10, 2020: Good Friday\n",
    "    April 2, 2021: Good Friday\n",
    "    April 15, 2022: Good Friday\n",
    "    April 7, 2023: Good Friday\n",
    "    March 29, 2024: Good Friday\n",
    "\n",
    "\n",
    "To proceed with cleaning as there are no missing dates which require propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Good Friday dates (for 2019 to 2024)\n",
    "good_fridays = pd.to_datetime([\n",
    "    '2019-04-19',  # Good Friday 2019\n",
    "    '2020-04-10',  # Good Friday 2020\n",
    "    '2021-04-02',  # Good Friday 2021\n",
    "    '2022-04-15',  # Good Friday 2022\n",
    "    '2023-04-07',  # Good Friday 2023\n",
    "    '2024-03-29',  # Good Friday 2024\n",
    "])\n",
    "\n",
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom business day calendar including these holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "I have decided not to use interpolation to 'fill' the missing dates in my stock market data. The missing dates occur on days when the stock market is not open, such as weekends and bank holidays. Interpolating data for non-trading days could lead to unreliable results and insights since there are no actual market transactions or price changes during these periods.\n",
    "\n",
    "Moving forward, I will explore the effect of aggregating the data to address the issue of missing dates due to market closures. Timeseries analysis requires a continuous date range, and since interpolation is not a suitable choice in this context, I will aggregate the data to a weekly/monthly level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "As expected, there are no missing values in the dataset. Yahoo Finance provides a clean dataset with minimal need for data cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting dataframe to csv\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.to_csv('../../data/microsoft_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "\n",
    "- format of graphs\n",
    "- add intro/conc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
