{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Data Cleaning\n",
    "----\n",
    "\n",
    "### Notebook Summary\n",
    "\n",
    "In this notebook, I will prepare the date-indexed microsoft data for forecasting. This process includes:\n",
    "\n",
    "- **Missing Dates:** Identify any missing dates in the dataset. If necessary, re-index the data to include all dates within the specified 5-year period.\n",
    "- **Missing Values:** Idendify and address any missing values in the dataset.\n",
    "- **Exporting Cleaned Data:** Export the processed dataframe to CSV ready for EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.api import tsa # time series analysis\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from csv, set index to be first column (our date column from 01-data-loading)\n",
    "msft_df = pd.read_csv('../../data/msft_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-12</th>\n",
       "      <td>131.667405</td>\n",
       "      <td>132.211832</td>\n",
       "      <td>130.731347</td>\n",
       "      <td>131.352203</td>\n",
       "      <td>27010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-13</th>\n",
       "      <td>131.600570</td>\n",
       "      <td>131.868011</td>\n",
       "      <td>130.444847</td>\n",
       "      <td>131.161209</td>\n",
       "      <td>23363100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-16</th>\n",
       "      <td>129.738001</td>\n",
       "      <td>130.568977</td>\n",
       "      <td>129.575628</td>\n",
       "      <td>130.215576</td>\n",
       "      <td>16731400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-17</th>\n",
       "      <td>130.817320</td>\n",
       "      <td>131.352201</td>\n",
       "      <td>130.311077</td>\n",
       "      <td>131.228027</td>\n",
       "      <td>17814200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-18</th>\n",
       "      <td>131.199380</td>\n",
       "      <td>132.450624</td>\n",
       "      <td>130.406604</td>\n",
       "      <td>132.307358</td>\n",
       "      <td>23982100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  \\\n",
       "2019-09-12  131.667405  132.211832  130.731347  131.352203  27010000   \n",
       "2019-09-13  131.600570  131.868011  130.444847  131.161209  23363100   \n",
       "2019-09-16  129.738001  130.568977  129.575628  130.215576  16731400   \n",
       "2019-09-17  130.817320  131.352201  130.311077  131.228027  17814200   \n",
       "2019-09-18  131.199380  132.450624  130.406604  132.307358  23982100   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "2019-09-12        0.0           0.0  \n",
       "2019-09-13        0.0           0.0  \n",
       "2019-09-16        0.0           0.0  \n",
       "2019-09-17        0.0           0.0  \n",
       "2019-09-18        0.0           0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking datatypes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1258 entries, 2019-09-12 to 2024-09-11\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          1258 non-null   float64\n",
      " 1   High          1258 non-null   float64\n",
      " 2   Low           1258 non-null   float64\n",
      " 3   Close         1258 non-null   float64\n",
      " 4   Volume        1258 non-null   int64  \n",
      " 5   Dividends     1258 non-null   float64\n",
      " 6   Stock Splits  1258 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 78.6+ KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Date to be datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.index = pd.to_datetime(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1258 entries, 2019-09-12 to 2024-09-11\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          1258 non-null   float64\n",
      " 1   High          1258 non-null   float64\n",
      " 2   Low           1258 non-null   float64\n",
      " 3   Close         1258 non-null   float64\n",
      " 4   Volume        1258 non-null   int64  \n",
      " 5   Dividends     1258 non-null   float64\n",
      " 6   Stock Splits  1258 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 78.6 KB\n"
     ]
    }
   ],
   "source": [
    "msft_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "Remaining datatypes are numerical and so we can continue with data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for missing dates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting first and last day from dataset\n",
    "first_day = msft_df.index.min()\n",
    "last_day = msft_df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1826 days 00:00:00')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate difference between last and first day\n",
    "last_day -  first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "There is a difference of 568 days, I assune these dates are non-trading days such as weekends and US bank holidays. These dates will need to be filled in order to perform timeseries forecasting since the methods to be used require a continour date range.\n",
    "\n",
    "See Appendix/Missing Dates for checking dates are non-trading days (weekends/bank holidays).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividends       0\n",
       "Stock Splits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "As expected, there are no missing values in the dataset. Yahoo Finance provides a clean dataset with minimal need for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing dates\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before filling the missing non-trading dates, I will need to reindex the  datarange to ensure the index (dates) are continous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with a DateTime index\n",
    "# Reindex to include all days (daily frequency)\n",
    "full_index = pd.date_range(start=first_day, end=last_day, freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df = msft_df.reindex(full_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking date range is now continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_range = pd.date_range(start=first_day, end=last_day, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_range.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No longer missing dates in date range, to continue in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            569\n",
       "High            569\n",
       "Low             569\n",
       "Close           569\n",
       "Volume          569\n",
       "Dividends       569\n",
       "Stock Splits    569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are missing values for the non-trading dates added during re-indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling values for missing dates using Interpolation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation is a method that estimates missing data points by assuming a linear relationship between the surrounding values. In other words, it looks at the numbers and before the null values and assumes the change between the two is smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation\n",
    "msft_df= msft_df.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividends       0\n",
       "Stock Splits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No longer see any null values, to export the cleaned dataset for EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting clean data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_df.to_csv('../../data/msft_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "\n",
    "After filling in the missing dates and values, the dataset is now clean and ready for further analysis. \n",
    "\n",
    "I will move on to Exploratory Data Analysis (EDA), where we can begin uncovering insights and patterns from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate full date range between first and last day\n",
    "# Using freq B to ensure dates reflect business days (excludes weekends and BHs)\n",
    "full_range = pd.date_range(start=first_day, end=last_day, freq=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = full_range.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "\n",
    "There are 47 missing days over the 5-year period. I will review these missing dates to determine if there is an underlying reason as to they are missing. Given that Yahoo Finance typically provides a clean dataset, I expect there may be specific reasons for these missing days, especially after considering business days only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-11-28', '2019-12-25', '2020-01-01', '2020-01-20',\n",
       "               '2020-02-17', '2020-04-10', '2020-05-25', '2020-07-03',\n",
       "               '2020-09-07', '2020-11-26', '2020-12-25', '2021-01-01',\n",
       "               '2021-01-18', '2021-02-15', '2021-04-02', '2021-05-31',\n",
       "               '2021-07-05', '2021-09-06', '2021-11-25', '2021-12-24',\n",
       "               '2022-01-17', '2022-02-21', '2022-04-15', '2022-05-30',\n",
       "               '2022-06-20', '2022-07-04', '2022-09-05', '2022-11-24',\n",
       "               '2022-12-26', '2023-01-02', '2023-01-16', '2023-02-20',\n",
       "               '2023-04-07', '2023-05-29', '2023-06-19', '2023-07-04',\n",
       "               '2023-09-04', '2023-11-23', '2023-12-25', '2024-01-01',\n",
       "               '2024-01-15', '2024-02-19', '2024-03-29', '2024-05-27',\n",
       "               '2024-06-19', '2024-07-04', '2024-09-02'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "On investigating the missing dates, it looks like they correspond to US bank holidays. Since the stock market is closed on these dates, we should exclude them in addition to weekends when analysing the dataset. To do this, I will use `holidays` library and `CustomBusinessDay` module to include US bank holidays in the list of dates to exclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bank_hols = holidays.UnitedStates(years=[2019,2020,2021,2022,2023,2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now excluding weekends AND US bank holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=us_bank_hols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcualting full date range between first and last day\n",
    "# Now excluding weekends and US holidays \n",
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-04-10', '2021-04-02', '2022-04-15', '2023-04-07',\n",
       "               '2024-03-29'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "Only 5 dates missing now, one per year which is intereseting.\n",
    "\n",
    "After looking into these dates futher, it appears these dates represent Good Friday holiday for each year. For some reason these holidays were not exlcuded in us_bank_hols: \n",
    "\n",
    "    April 10, 2020: Good Friday\n",
    "    April 2, 2021: Good Friday\n",
    "    April 15, 2022: Good Friday\n",
    "    April 7, 2023: Good Friday\n",
    "    March 29, 2024: Good Friday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Good Friday dates (for 2019 to 2024)\n",
    "good_fridays = pd.to_datetime([\n",
    "    '2019-04-19',  # Good Friday 2019\n",
    "    '2020-04-10',  # Good Friday 2020\n",
    "    '2021-04-02',  # Good Friday 2021\n",
    "    '2022-04-15',  # Good Friday 2022\n",
    "    '2023-04-07',  # Good Friday 2023\n",
    "    '2024-03-29',  # Good Friday 2024\n",
    "])\n",
    "\n",
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holidays = pd.to_datetime(list(us_bank_hols) + list(good_fridays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom business day calendar including these holidays\n",
    "cust_business_days = CustomBusinessDay(holidays=all_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_days = pd.date_range(start=first_day, end=last_day, freq=cust_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_days.difference(msft_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirms missing dates are all either the weekends (not business days) or US bank holidays. Both of which are non-trading days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
